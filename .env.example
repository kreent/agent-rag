# ═══════════════════════════════════════════════════════════
# CONFIGURACIÓN DEL RAG AGENT
# Copiar a .env y completar los valores
# ═══════════════════════════════════════════════════════════

# REQUERIDO: API Key de Anthropic
ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxx

# Proveedor LLM: anthropic | openai_compatible
LLM_PROVIDER=anthropic

# Modelo Anthropic (si LLM_PROVIDER=anthropic)
ANTHROPIC_MODEL=claude-sonnet-4-20250514

# Config OpenAI-compatible (Ollama, Groq, OpenRouter, etc.)
# OPENAI_BASE_URL=http://host.docker.internal:11434/v1
# OPENAI_API_KEY=ollama
# OPENAI_MODEL=qwen3:8b

# Tu API de datos
API_BASE_URL=https://tu-api.com
API_KEY=tu-api-key-si-es-necesario

# Ruta a los documentos (en el servidor)
FILES_PATH=/files

# URL pública para acceder a los documentos (para generar links en las respuestas)
FILES_BASE_URL=http://tu-servidor.com/sites/default/files

# Configuración de chunking
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Modelo de embeddings (multilingüe recomendado para español)
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

# Puerto de la API
PORT=8000

# CORS (dominios permitidos, separados por coma)
CORS_ORIGINS=https://tu-frontend.com,https://admin.tu-app.com

# Debug mode (true/false)
DEBUG=false
